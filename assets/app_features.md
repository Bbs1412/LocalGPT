1. Runs Locally with Streamlit
2. Any model from Ollama can be used
3. Supports Streaming Responses with Live Preview
4. Support attachments like Images (currently only images are supported)
5. Supports Threads (Chat Archives)
6. Can rename, create and delete threads
7. Threads are listed as per last used
8. Remembers the last model used with thread, which is auto-loaded next time
9. Can switch between models within same thread
10. Running models can be checked and stopped